"""WebSocket ì‹¤ì‹œê°„ ìŒì„± ìŠ¤íŠ¸ë¦¬ë° API

ì‹¤ì‹œê°„ ì–‘ë°©í–¥ ìŒì„± í†µì‹ ì„ ìœ„í•œ WebSocket ì—”ë“œí¬ì¸íŠ¸.

ì‚¬ìš© íë¦„:
1. í´ë¼ì´ì–¸íŠ¸ê°€ WebSocket ì—°ê²° (/api/v1/voice/ws/{session_id})
2. audio_start ë©”ì‹œì§€ë¡œ ìŒì„± ì „ì†¡ ì‹œì‘ ì•Œë¦¼
3. audio_chunk ë©”ì‹œì§€ë¡œ ìŒì„± ë°ì´í„° ì²­í¬ ì „ì†¡
4. audio_end ë©”ì‹œì§€ë¡œ ìŒì„± ì „ì†¡ ì¢…ë£Œ
5. ì„œë²„ê°€ STT â†’ ì›Œí¬í”Œë¡œìš° â†’ TTS ì²˜ë¦¬ í›„ ì‘ë‹µ

ë©”ì‹œì§€ í˜•ì‹:
- í´ë¼ì´ì–¸íŠ¸ â†’ ì„œë²„: JSON {"type": "...", "data": {...}}
- ì„œë²„ â†’ í´ë¼ì´ì–¸íŠ¸: JSON {"type": "...", "data": {...}}
"""

import asyncio
import base64
import json
import logging
import time
from typing import Optional

from fastapi import APIRouter, WebSocket, WebSocketDisconnect

from app.schemas.chat import ChatRequest
from app.schemas.voice import WSMessageType
from app.services.workflow_service import process_chat_message
from app.services.voice.stt_service import AICCSTTService, STTError, pcm_to_wav
from app.services.voice.tts_service_google import AICCGoogleTTSService, TTSError
from app.services.vad import HybridVADStream, SileroVADStream
from app.services.session_manager import session_manager

logger = logging.getLogger(__name__)
router = APIRouter()


class VoiceWebSocketManager:
    """WebSocket ì—°ê²° ê´€ë¦¬ì"""
    
    def __init__(self):
        # session_id â†’ WebSocket ë§¤í•‘
        self.active_connections: dict[str, WebSocket] = {}
    
    async def connect(self, session_id: str, websocket: WebSocket):
        """ì—°ê²° ìˆ˜ë½ ë° ë“±ë¡"""
        await websocket.accept()
        self.active_connections[session_id] = websocket
        logger.info(f"[WS] ì—°ê²°ë¨ - ì„¸ì…˜: {session_id}")
    
    def disconnect(self, session_id: str):
        """ì—°ê²° í•´ì œ"""
        if session_id in self.active_connections:
            del self.active_connections[session_id]
            logger.info(f"[WS] ì—°ê²° í•´ì œ - ì„¸ì…˜: {session_id}")
    
    async def send_json(self, session_id: str, message: dict):
        """JSON ë©”ì‹œì§€ ì „ì†¡"""
        if session_id in self.active_connections:
            await self.active_connections[session_id].send_json(message)
    
    async def send_message(
        self, 
        session_id: str, 
        msg_type: str, 
        data: Optional[dict] = None
    ):
        """íƒ€ì…ì´ ìˆëŠ” ë©”ì‹œì§€ ì „ì†¡"""
        message = {
            "type": msg_type,
            "data": data or {},
            "timestamp": time.time(),
        }
        await self.send_json(session_id, message)


# ì „ì—­ ë§¤ë‹ˆì € ì¸ìŠ¤í„´ìŠ¤
ws_manager = VoiceWebSocketManager()


@router.websocket("/ws/{session_id}")
async def voice_websocket_endpoint(websocket: WebSocket, session_id: str):
    """
    ğŸ¤ ì‹¤ì‹œê°„ ìŒì„± WebSocket ì—”ë“œí¬ì¸íŠ¸
    
    ì—°ê²° URL: ws://localhost:8000/api/v1/voice/ws/{session_id}
    
    í´ë¼ì´ì–¸íŠ¸ â†’ ì„œë²„ ë©”ì‹œì§€:
    - audio_start: ìŒì„± ì „ì†¡ ì‹œì‘ {"type": "audio_start", "data": {"language": "ko", "tts_voice": "ko-KR-Neural2-B"}}
    - audio_chunk: ìŒì„± ë°ì´í„° {"type": "audio_chunk", "data": {"audio_base64": "..."}}
    - audio_end: ìŒì„± ì „ì†¡ ì¢…ë£Œ {"type": "audio_end"}
    - text_message: í…ìŠ¤íŠ¸ ì§ì ‘ ì „ì†¡ {"type": "text_message", "data": {"text": "..."}}
    - ping: ì—°ê²° í™•ì¸ {"type": "ping"}
    
    ì„œë²„ â†’ í´ë¼ì´ì–¸íŠ¸ ë©”ì‹œì§€:
    - connected: ì—°ê²° ì™„ë£Œ
    - stt_result: STT ê²°ê³¼
    - ai_response: AI ì‘ë‹µ
    - tts_audio: TTS ìŒì„±
    - error: ì—ëŸ¬
    - pong: Ping ì‘ë‹µ
    """
    await ws_manager.connect(session_id, websocket)
    
    # ì—°ê²° ì™„ë£Œ ë©”ì‹œì§€
    await ws_manager.send_message(
        session_id,
        WSMessageType.CONNECTED,
        {"session_id": session_id, "message": "ì—°ê²°ë˜ì—ˆìŠµë‹ˆë‹¤."}
    )
    
    # ìŒì„± ë°ì´í„° ë²„í¼
    audio_buffer: list[bytes] = []
    audio_settings: dict = {
        "language": "ko",
        "tts_voice": "ko-KR-Neural2-B",  # Google TTS ê¸°ë³¸ ìŒì„±
        "diarize": False,
    }
    
    try:
        while True:
            # ë©”ì‹œì§€ ìˆ˜ì‹ 
            raw_message = await websocket.receive()
            
            # ì—°ê²° ì¢…ë£Œ í™•ì¸
            if raw_message.get("type") == "websocket.disconnect":
                break
            
            # ë°”ì´ë„ˆë¦¬ ë°ì´í„° (ì§ì ‘ ì˜¤ë””ì˜¤ ì²­í¬)
            if "bytes" in raw_message:
                audio_buffer.append(raw_message["bytes"])
                continue
            
            # JSON ë©”ì‹œì§€
            if "text" in raw_message:
                try:
                    message = json.loads(raw_message["text"])
                except json.JSONDecodeError:
                    await ws_manager.send_message(
                        session_id,
                        WSMessageType.ERROR,
                        {"error": "ì˜ëª»ëœ JSON í˜•ì‹ì…ë‹ˆë‹¤."}
                    )
                    continue
                
                msg_type = message.get("type", "")
                msg_data = message.get("data", {})
                
                # ========== ë©”ì‹œì§€ íƒ€ì…ë³„ ì²˜ë¦¬ ==========
                
                if msg_type == WSMessageType.PING:
                    # Ping-Pong
                    await ws_manager.send_message(session_id, WSMessageType.PONG)
                
                elif msg_type == WSMessageType.AUDIO_START:
                    # ìŒì„± ì „ì†¡ ì‹œì‘
                    audio_buffer.clear()
                    audio_settings.update({
                        "language": msg_data.get("language", "ko"),
                        "tts_voice": msg_data.get("tts_voice", "ko-KR-Neural2-B"),  # Google TTS ê¸°ë³¸ ìŒì„±
                        "diarize": msg_data.get("diarize", False),
                    })
                    logger.info(f"[WS] ìŒì„± ì‹œì‘ - ì„¸ì…˜: {session_id}, ì„¤ì •: {audio_settings}")
                
                elif msg_type == WSMessageType.AUDIO_CHUNK:
                    # ìŒì„± ë°ì´í„° ì²­í¬ (Base64)
                    audio_base64 = msg_data.get("audio_base64", "")
                    if audio_base64:
                        try:
                            audio_bytes = base64.b64decode(audio_base64)
                            audio_buffer.append(audio_bytes)
                        except Exception as e:
                            logger.warning(f"[WS] Base64 ë””ì½”ë”© ì‹¤íŒ¨: {e}")
                
                elif msg_type == WSMessageType.AUDIO_END:
                    # ìŒì„± ì „ì†¡ ì¢…ë£Œ â†’ ì²˜ë¦¬ ì‹œì‘
                    if audio_buffer:
                        await process_audio_and_respond(
                            session_id=session_id,
                            audio_data=b"".join(audio_buffer),
                            settings=audio_settings,
                        )
                        audio_buffer.clear()
                    else:
                        await ws_manager.send_message(
                            session_id,
                            WSMessageType.ERROR,
                            {"error": "ìŒì„± ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."}
                        )
                
                elif msg_type == WSMessageType.TEXT_MESSAGE:
                    # í…ìŠ¤íŠ¸ ì§ì ‘ ì „ì†¡ (STT ê±´ë„ˆë›°ê¸°)
                    text = msg_data.get("text", "").strip()
                    if text:
                        await process_text_and_respond(
                            session_id=session_id,
                            text=text,
                            tts_voice=audio_settings.get("tts_voice", "ko-KR-Neural2-B"),
                        )
                    else:
                        await ws_manager.send_message(
                            session_id,
                            WSMessageType.ERROR,
                            {"error": "í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤."}
                        )
                
                else:
                    await ws_manager.send_message(
                        session_id,
                        WSMessageType.ERROR,
                        {"error": f"ì•Œ ìˆ˜ ì—†ëŠ” ë©”ì‹œì§€ íƒ€ì…: {msg_type}"}
                    )
    
    except WebSocketDisconnect:
        logger.info(f"[WS] í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ì¢…ë£Œ - ì„¸ì…˜: {session_id}")
    except Exception as e:
        logger.error(f"[WS] ì˜¤ë¥˜ ë°œìƒ - ì„¸ì…˜: {session_id}, ì˜¤ë¥˜: {e}", exc_info=True)
        try:
            await ws_manager.send_message(
                session_id,
                WSMessageType.ERROR,
                {"error": f"ì„œë²„ ì˜¤ë¥˜: {str(e)}"}
            )
        except:
            pass
    finally:
        ws_manager.disconnect(session_id)


async def process_audio_and_respond(
    session_id: str,
    audio_data: bytes,
    settings: dict,
):
    """ìŒì„± ë°ì´í„° ì²˜ë¦¬ ë° ì‘ë‹µ (STT â†’ ì›Œí¬í”Œë¡œìš° â†’ TTS)"""
    
    try:
        # ========== 1. STT ==========
        logger.info(f"[WS] STT ì‹œì‘ - ì„¸ì…˜: {session_id}, í¬ê¸°: {len(audio_data)} bytes")
        
        try:
            stt_service = AICCSTTService.get_instance()
            stt_result = stt_service.transcribe(
                audio_data,
                language=settings.get("language", "ko"),
                diarize=settings.get("diarize", False),
            )
            transcribed_text = stt_result.text
        except STTError as e:
            await ws_manager.send_message(
                session_id,
                WSMessageType.ERROR,
                {"error": f"ìŒì„± ì¸ì‹ ì‹¤íŒ¨: {str(e)}"}
            )
            return
        
        if not transcribed_text.strip():
            await ws_manager.send_message(
                session_id,
                WSMessageType.ERROR,
                {"error": "ìŒì„±ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¸ì‹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}
            )
            return
        
        # STT ê²°ê³¼ ì „ì†¡
        await ws_manager.send_message(
            session_id,
            WSMessageType.STT_RESULT,
            {
                "text": transcribed_text,
                "is_final": True,
                "language": stt_result.language,
            }
        )
        
        # ========== 2. ì›Œí¬í”Œë¡œìš° + TTS ==========
        await process_text_and_respond(
            session_id=session_id,
            text=transcribed_text,
            tts_voice=settings.get("tts_voice", "ko-KR-Neural2-B"),
        )
        
    except Exception as e:
        logger.error(f"[WS] ì²˜ë¦¬ ì˜¤ë¥˜ - ì„¸ì…˜: {session_id}, ì˜¤ë¥˜: {e}", exc_info=True)
        await ws_manager.send_message(
            session_id,
            WSMessageType.ERROR,
            {"error": f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}"}
        )


async def process_text_and_respond(
    session_id: str,
    text: str,
    tts_voice: str = "ko-KR-Neural2-B",
):
    """í…ìŠ¤íŠ¸ ì²˜ë¦¬ ë° ì‘ë‹µ (ì›Œí¬í”Œë¡œìš° â†’ TTS)

    ì´ê´€ ëª¨ë“œì¸ ê²½ìš° AI ì›Œí¬í”Œë¡œìš°ë¥¼ ìŠ¤í‚µí•˜ê³  STT ê²°ê³¼ë§Œ ì „ì†¡í•©ë‹ˆë‹¤.
    """

    try:
        # ========== ì´ê´€ ìƒíƒœ í™•ì¸ ==========
        if session_manager.is_handover_mode(session_id):
            logger.info(f"[WS] ì´ê´€ ëª¨ë“œ - AI ì›Œí¬í”Œë¡œìš° ìŠ¤í‚µ - ì„¸ì…˜: {session_id}")
            # ì´ê´€ ëª¨ë“œì—ì„œëŠ” AI ì‘ë‹µ ì—†ì´ ì™„ë£Œ (í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ìƒë‹´ì›ì—ê²Œ ë©”ì‹œì§€ ì „ì†¡)
            await ws_manager.send_message(
                session_id,
                WSMessageType.AI_RESPONSE,
                {
                    "text": "",  # ë¹ˆ ì‘ë‹µ
                    "intent": "HANDOVER_MODE",
                    "suggested_action": "HANDOVER",
                    "is_handover_mode": True,  # ì´ê´€ ëª¨ë“œ í‘œì‹œ
                }
            )
            return

        # ========== ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ==========
        logger.info(f"[WS] ì›Œí¬í”Œë¡œìš° ì‹œì‘ - ì„¸ì…˜: {session_id}, í…ìŠ¤íŠ¸: {text[:30]}...")

        chat_request = ChatRequest(
            session_id=session_id,
            user_message=text,
        )
        chat_response = await process_chat_message(chat_request)

        # AI ì‘ë‹µ ì „ì†¡ (handover_status, is_human_required_flow, is_session_end í¬í•¨)
        await ws_manager.send_message(
            session_id,
            WSMessageType.AI_RESPONSE,
            {
                "text": chat_response.ai_message,
                "intent": chat_response.intent.value if hasattr(chat_response.intent, 'value') else str(chat_response.intent),
                "suggested_action": chat_response.suggested_action.value if hasattr(chat_response.suggested_action, 'value') else str(chat_response.suggested_action),
                "handover_status": chat_response.handover_status,  # í•¸ë“œì˜¤ë²„ ìƒíƒœ ì¶”ê°€
                "is_human_required_flow": chat_response.is_human_required_flow,  # HUMAN_REQUIRED í”Œë¡œìš° ì—¬ë¶€
                "is_session_end": chat_response.is_session_end,  # ì„¸ì…˜ ì¢…ë£Œ ì—¬ë¶€
            }
        )

        # ========== TTS ==========
        logger.info(f"[WS] TTS ì‹œì‘ - ì„¸ì…˜: {session_id}")

        try:
            tts_service = AICCGoogleTTSService.get_instance()
            tts_audio = tts_service.synthesize(
                chat_response.ai_message,
                voice=tts_voice,
            )

            # TTS ìŒì„± ì „ì†¡
            await ws_manager.send_message(
                session_id,
                WSMessageType.TTS_AUDIO,
                {
                    "audio_base64": base64.b64encode(tts_audio).decode("utf-8"),
                    "format": "mp3",
                    "is_final": True,
                }
            )

            logger.info(f"[WS] ì‘ë‹µ ì™„ë£Œ - ì„¸ì…˜: {session_id}")

        except TTSError as e:
            logger.warning(f"[WS] TTS ì‹¤íŒ¨ - ì„¸ì…˜: {session_id}, ì˜¤ë¥˜: {e}")
            # TTS ì‹¤íŒ¨í•´ë„ í…ìŠ¤íŠ¸ ì‘ë‹µì€ ì´ë¯¸ ì „ì†¡ë¨

    except Exception as e:
        logger.error(f"[WS] ì²˜ë¦¬ ì˜¤ë¥˜ - ì„¸ì…˜: {session_id}, ì˜¤ë¥˜: {e}", exc_info=True)
        await ws_manager.send_message(
            session_id,
            WSMessageType.ERROR,
            {"error": f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}"}
        )


# ========== ì—°ê²° ìƒíƒœ í™•ì¸ API ==========

@router.get("/ws/connections")
async def get_active_connections():
    """í˜„ì¬ í™œì„± WebSocket ì—°ê²° ëª©ë¡ (ë””ë²„ê¹…ìš©)"""
    return {
        "active_sessions": list(ws_manager.active_connections.keys()),
        "count": len(ws_manager.active_connections),
    }


# ========== VAD ê¸°ë°˜ ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì—”ë“œí¬ì¸íŠ¸ ==========

class VoiceStreamSession:
    """VAD ê¸°ë°˜ ìŒì„± ìŠ¤íŠ¸ë¦¬ë° ì„¸ì…˜ ê´€ë¦¬ (Hybrid VAD: WebRTC + Silero)"""

    def __init__(self, session_id: str, websocket: WebSocket):
        self.session_id = session_id
        self.websocket = websocket

        # Hybrid VAD ì´ˆê¸°í™”: WebRTC (ë¹ ë¥¸ ì„ í•„í„°) + Silero (ì •í™•í•œ í™•ì¸)
        silero_vad = SileroVADStream(
            sample_rate=16000,
            frame_ms=40,  # SileroëŠ” 40ms í”„ë ˆì„
            threshold=0.3,  # ì†ŒìŒ í™˜ê²½ì—ì„œ ë‚®ì€ ì„ê³„ê°’ ì‚¬ìš©
        )
        self.vad = HybridVADStream(
            silero_vad,
            sample_rate=16000,
            frame_ms=30,  # WebRTCëŠ” 30ms í”„ë ˆì„ (Silero ìµœì†Œ ìš”êµ¬ì‚¬í•­ ì¶©ì¡±)
            aggressiveness=2,  # ì¤‘ê°„ ìˆ˜ì¤€ì˜ ë¯¼ê°ë„
            min_speech_ms=150,  # ìµœì†Œ 150ms ìŒì„±
            max_silence_ms=2000,  # 2ì´ˆ ì¹¨ë¬µ í›„ ìŒì„± ì¢…ë£Œ
            mode="and",  # WebRTCì™€ Silero ëª¨ë‘ ìŒì„±ìœ¼ë¡œ íŒë‹¨í•´ì•¼ í•¨
        )

        self.is_active = True
        self.is_speaking = False
        self.audio_buffer: list[bytes] = []
        self.last_activity_time = time.time()
        self.audio_settings: dict = {
            "language": "ko",
            "tts_voice": "ko-KR-Neural2-B",
        }
        self._processing_task: asyncio.Task | None = None  # ì§„í–‰ ì¤‘ì¸ STT/AI/TTS ì‘ì—…

    async def send_message(self, msg_type: str, data: dict):
        """í´ë¼ì´ì–¸íŠ¸ì— ë©”ì‹œì§€ ì „ì†¡"""
        if not self.is_active:
            return  # ì„¸ì…˜ì´ ë¹„í™œì„±í™”ë˜ë©´ ì „ì†¡ ì•ˆí•¨
        try:
            await self.websocket.send_json({
                'type': msg_type,
                'data': data,
                'timestamp': time.time() * 1000
            })
        except Exception as e:
            logger.error(f"ë©”ì‹œì§€ ì „ì†¡ ì˜¤ë¥˜: {e}")
            self.is_active = False  # ì „ì†¡ ì‹¤íŒ¨ ì‹œ ì„¸ì…˜ ë¹„í™œì„±í™”

    async def process_audio(self, audio_data: bytes):
        """ì˜¤ë””ì˜¤ ë°ì´í„° ì²˜ë¦¬ ë° Hybrid VAD ìˆ˜í–‰ (WebRTC + Silero)"""
        if not self.is_active:
            return  # ì„¸ì…˜ì´ ë¹„í™œì„±í™”ë˜ë©´ ì²˜ë¦¬ ì•ˆí•¨
        try:
            # ì´ì „ VAD ìƒíƒœ ì €ì¥ (speech_start ê°ì§€ìš©)
            was_in_speech = self.vad._in_speech

            # Hybrid VADë¡œ ìŒì„± ì„¸ê·¸ë¨¼íŠ¸ ê°ì§€
            segments = self.vad.feed(audio_data)

            # í˜„ì¬ VAD ìƒíƒœ
            is_in_speech = self.vad._in_speech

            # ìŒì„± ì‹œì‘ ê°ì§€ (ì´ì „: ì¹¨ë¬µ â†’ í˜„ì¬: ìŒì„±)
            if not was_in_speech and is_in_speech:
                self.is_speaking = True
                self.audio_buffer = []  # ìƒˆ ìŒì„± ì‹œì‘ ì‹œ ë²„í¼ ì´ˆê¸°í™”
                logger.info(f"[{self.session_id}] ìŒì„± ì‹œì‘")
                await self.send_message('vad_result', {
                    'is_speech': True,
                    'speech_prob': 0.0,
                    'event': 'speech_start',
                })

            # ìŒì„± ì¤‘ì´ë©´ ë²„í¼ì— ì €ì¥
            if is_in_speech or self.is_speaking:
                self.audio_buffer.append(audio_data)
                # ìŒì„± ì§€ì† ìƒíƒœ ì „ì†¡ (ì‹¤ì œ VAD ìƒíƒœ ë°˜ì˜)
                if not segments:
                    await self.send_message('vad_result', {
                        'is_speech': is_in_speech,  # ì‹¤ì œ VAD ìƒíƒœ
                        'speech_prob': 0.0,  # HybridVADëŠ” í”„ë ˆì„ë³„ í™•ë¥  ì œê³µ ì•ˆí•¨
                        'event': 'speech_continue' if is_in_speech else 'silence_in_buffer',
                    })

            # ìŒì„± ì„¸ê·¸ë¨¼íŠ¸ ì™„ë£Œ ì‹œ (2ì´ˆ ì¹¨ë¬µ í›„)
            for segment in segments:
                if segment.is_speech:
                    logger.info(f"[{self.session_id}] ìŒì„± ì„¸ê·¸ë¨¼íŠ¸ ì™„ë£Œ - "
                              f"start: {segment.start_ms}ms, end: {segment.end_ms}ms, "
                              f"duration: {segment.end_ms - segment.start_ms}ms")

                    # ìŒì„± ì¢…ë£Œ ì´ë²¤íŠ¸ ì „ì†¡
                    await self.send_message('vad_result', {
                        'is_speech': False,
                        'speech_prob': segment.score or 0.0,
                        'event': 'speech_end',
                    })

                    # ìë™ ì „ì†¡ ì´ë²¤íŠ¸
                    await self.send_message('auto_send', {
                        'reason': 'silence_detected',
                        'buffer_chunks': len(self.audio_buffer),
                        'duration_ms': segment.end_ms - segment.start_ms,
                    })

                    # ë²„í¼ì— ë°ì´í„°ê°€ ìˆìœ¼ë©´ STT/AI/TTS ì²˜ë¦¬
                    if self.audio_buffer:
                        audio_data_combined = b"".join(self.audio_buffer)
                        self.audio_buffer = []

                        # ë¹„ë™ê¸°ë¡œ ì²˜ë¦¬ ì‹œì‘ (Task ì¶”ì )
                        self._processing_task = asyncio.create_task(self._process_speech(audio_data_combined))

                    self.is_speaking = False

            # ì¹¨ë¬µ ìƒíƒœ (ìŒì„± ì¤‘ì´ ì•„ë‹ ë•Œ)
            if not is_in_speech and not self.is_speaking and not segments:
                await self.send_message('vad_result', {
                    'is_speech': False,
                    'speech_prob': 0.0,
                    'event': 'silence',
                })

            self.last_activity_time = time.time()

        except Exception as e:
            logger.error(f"ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")

    async def _process_speech(self, audio_data: bytes):
        """ìŒì„± ë°ì´í„° STT â†’ AI â†’ TTS ì²˜ë¦¬

        ì´ê´€ ëª¨ë“œì¸ ê²½ìš° AI ì›Œí¬í”Œë¡œìš°ë¥¼ ìŠ¤í‚µí•˜ê³  STT ê²°ê³¼ë§Œ ì „ì†¡í•©ë‹ˆë‹¤.
        """
        try:
            # 1. STT
            logger.info(f"[{self.session_id}] STT ì‹œì‘ - í¬ê¸°: {len(audio_data)} bytes")

            try:
                # Raw INT16 PCMì„ WAV í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (VITO STT ìš”êµ¬ì‚¬í•­)
                wav_data = pcm_to_wav(audio_data, sample_rate=16000, channels=1, sample_width=2)
                logger.info(f"[{self.session_id}] PCM â†’ WAV ë³€í™˜ ì™„ë£Œ - í¬ê¸°: {len(wav_data)} bytes")

                stt_service = AICCSTTService.get_instance()
                stt_result = stt_service.transcribe(
                    wav_data,
                    language=self.audio_settings.get("language", "ko"),
                )
                transcribed_text = stt_result.text
            except STTError as e:
                await self.send_message('error', {"error": f"ìŒì„± ì¸ì‹ ì‹¤íŒ¨: {str(e)}"})
                return

            if not transcribed_text.strip():
                await self.send_message('error', {"error": "ìŒì„±ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¸ì‹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."})
                return

            # STT ê²°ê³¼ ì „ì†¡
            await self.send_message('stt_result', {
                'text': transcribed_text,
                'is_final': True,
            })

            # ========== ì´ê´€ ìƒíƒœ í™•ì¸ ==========
            if session_manager.is_handover_mode(self.session_id):
                logger.info(f"[{self.session_id}] ì´ê´€ ëª¨ë“œ - AI ì›Œí¬í”Œë¡œìš° ìŠ¤í‚µ")
                # ì´ê´€ ëª¨ë“œì—ì„œëŠ” AI ì‘ë‹µ ì—†ì´ ì™„ë£Œ (í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ìƒë‹´ì›ì—ê²Œ ë©”ì‹œì§€ ì „ì†¡)
                await self.send_message('ai_response', {
                    'text': '',  # ë¹ˆ ì‘ë‹µ
                    'intent': 'HANDOVER_MODE',
                    'suggested_action': 'HANDOVER',
                    'is_handover_mode': True,  # ì´ê´€ ëª¨ë“œ í‘œì‹œ
                })
                await self.send_message('completed', {
                    'message': 'ì´ê´€ ëª¨ë“œ - STTë§Œ ì²˜ë¦¬',
                    'final_text': transcribed_text,
                    'is_handover_mode': True,
                })
                return

            # 2. AI ì›Œí¬í”Œë¡œìš°
            logger.info(f"[{self.session_id}] ì›Œí¬í”Œë¡œìš° ì‹œì‘ - í…ìŠ¤íŠ¸: {transcribed_text[:30]}...")

            chat_request = ChatRequest(
                session_id=self.session_id,
                user_message=transcribed_text,
            )
            chat_response = await process_chat_message(chat_request)

            # AI ì‘ë‹µ ì „ì†¡ (handover_status, is_human_required_flow, is_session_end í¬í•¨)
            await self.send_message('ai_response', {
                'text': chat_response.ai_message,
                'intent': chat_response.intent.value if hasattr(chat_response.intent, 'value') else str(chat_response.intent),
                'suggested_action': chat_response.suggested_action.value if hasattr(chat_response.suggested_action, 'value') else str(chat_response.suggested_action),
                'handover_status': chat_response.handover_status,  # í•¸ë“œì˜¤ë²„ ìƒíƒœ ì¶”ê°€
                'is_human_required_flow': chat_response.is_human_required_flow,  # HUMAN_REQUIRED í”Œë¡œìš° ì—¬ë¶€
                'is_session_end': chat_response.is_session_end,  # ì„¸ì…˜ ì¢…ë£Œ ì—¬ë¶€
            })

            # 3. TTS (Google TTS ì‚¬ìš©)
            logger.info(f"[{self.session_id}] TTS ì‹œì‘")

            try:
                tts_service = AICCGoogleTTSService.get_instance()
                tts_audio = tts_service.synthesize(
                    chat_response.ai_message,
                    voice=self.audio_settings.get("tts_voice", "ko-KR-Neural2-B"),
                )

                # TTS ìŒì„± ì „ì†¡
                await self.send_message('tts_chunk', {
                    'audio_base64': base64.b64encode(tts_audio).decode("utf-8"),
                    'format': 'mp3',
                    'chunk_index': 0,
                })

                logger.info(f"[{self.session_id}] ì‘ë‹µ ì™„ë£Œ")

            except TTSError as e:
                logger.warning(f"[{self.session_id}] TTS ì‹¤íŒ¨: {e}")

            # ì™„ë£Œ ë©”ì‹œì§€
            await self.send_message('completed', {
                'message': 'ì²˜ë¦¬ ì™„ë£Œ',
                'final_text': transcribed_text,
            })

        except Exception as e:
            logger.error(f"[{self.session_id}] ì²˜ë¦¬ ì˜¤ë¥˜: {e}", exc_info=True)
            await self.send_message('error', {"error": f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}"})

    def reset(self):
        """ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”"""
        self.vad.reset()
        self.is_speaking = False
        self.audio_buffer = []


@router.websocket("/streaming/{session_id}")
async def voice_streaming(websocket: WebSocket, session_id: str):
    """
    VAD ê¸°ë°˜ ì–‘ë°©í–¥ ìŒì„± ìŠ¤íŠ¸ë¦¬ë° WebSocket ì—”ë“œí¬ì¸íŠ¸

    í´ë¼ì´ì–¸íŠ¸ â†’ ì„œë²„:
    - binary: INT16 PCM ì˜¤ë””ì˜¤ ë°ì´í„° (16kHz)
    - text "EOS": ìŠ¤íŠ¸ë¦¬ë° ì¢…ë£Œ
    - text "RESET": VAD ìƒíƒœ ì´ˆê¸°í™”

    ì„œë²„ â†’ í´ë¼ì´ì–¸íŠ¸:
    - vad_result: VAD ê°ì§€ ê²°ê³¼ {is_speech, speech_prob, event}
    - auto_send: ìë™ ì „ì†¡ íŠ¸ë¦¬ê±° (2ì´ˆ ì¹¨ë¬µ)
    - stt_result: STT ê²°ê³¼ {text, is_final}
    - ai_response: AI ì‘ë‹µ {text, intent, suggested_action}
    - tts_chunk: TTS ì˜¤ë””ì˜¤ {audio_base64, format}
    - completed: ì²˜ë¦¬ ì™„ë£Œ
    - error: ì˜¤ë¥˜ ë©”ì‹œì§€
    """
    await websocket.accept()

    session = VoiceStreamSession(session_id, websocket)
    logger.info(f"[{session_id}] WebSocket ì—°ê²°ë¨ (VAD ìŠ¤íŠ¸ë¦¬ë°)")

    try:
        # ì—°ê²° ì„±ê³µ ë©”ì‹œì§€
        await session.send_message('connected', {
            'session_id': session_id,
            'message': 'Hybrid VAD (WebRTC + Silero) ìŠ¤íŠ¸ë¦¬ë° ì—°ê²° ì™„ë£Œ',
            'vad_config': {
                'engine': 'hybrid',
                'mode': 'and',
                'webrtc_aggressiveness': 3,
                'silero_threshold': 0.3,
                'sample_rate': 16000,
                'min_speech_ms': 150,
                'max_silence_ms': 2000,
            }
        })

        while session.is_active:
            try:
                # ë©”ì‹œì§€ ìˆ˜ì‹  (íƒ€ì„ì•„ì›ƒ 60ì´ˆ)
                message = await asyncio.wait_for(
                    websocket.receive(),
                    timeout=60.0
                )

                if message['type'] == 'websocket.disconnect':
                    break

                # ë°”ì´ë„ˆë¦¬ ì˜¤ë””ì˜¤ ë°ì´í„°
                if 'bytes' in message:
                    await session.process_audio(message['bytes'])

                # í…ìŠ¤íŠ¸ ëª…ë ¹
                elif 'text' in message:
                    text = message['text'].strip()

                    if text == 'EOS':
                        logger.info(f"[{session_id}] EOS ìˆ˜ì‹ ")

                        # ë²„í¼ì— ë‚¨ì€ ë°ì´í„° ì²˜ë¦¬ (ì™„ë£Œê¹Œì§€ ëŒ€ê¸°)
                        if session.audio_buffer:
                            audio_data_combined = b"".join(session.audio_buffer)
                            session.audio_buffer = []
                            await session._process_speech(audio_data_combined)
                        elif session._processing_task and not session._processing_task.done():
                            # VADê°€ ì´ë¯¸ ì²˜ë¦¬ë¥¼ ì‹œì‘í•œ ê²½ìš°, ì™„ë£Œë  ë•Œê¹Œì§€ ëŒ€ê¸°
                            logger.info(f"[{session_id}] ì§„í–‰ ì¤‘ì¸ ì²˜ë¦¬ ì™„ë£Œ ëŒ€ê¸°...")
                            await session._processing_task
                        else:
                            # ë²„í¼ë„ ë¹„ì–´ìˆê³  ì§„í–‰ ì¤‘ì¸ ì‘ì—…ë„ ì—†ìœ¼ë©´ ì™„ë£Œ ë©”ì‹œì§€ ì „ì†¡
                            await session.send_message('completed', {
                                'message': 'EOS ì²˜ë¦¬ ì™„ë£Œ (ë²„í¼ ì—†ìŒ)'
                            })

                        session.reset()

                    elif text == 'RESET':
                        logger.info(f"[{session_id}] RESET ìˆ˜ì‹ ")
                        session.reset()
                        await session.send_message('reset', {
                            'message': 'VAD ìƒíƒœ ì´ˆê¸°í™” ì™„ë£Œ'
                        })

                    elif text == 'ping':
                        await session.send_message('pong', {})

            except asyncio.TimeoutError:
                # íƒ€ì„ì•„ì›ƒ ì‹œ ping ì „ì†¡
                await session.send_message('ping', {})

    except WebSocketDisconnect:
        logger.info(f"[{session_id}] í´ë¼ì´ì–¸íŠ¸ ì—°ê²° í•´ì œ")
    except Exception as e:
        logger.error(f"[{session_id}] WebSocket ì˜¤ë¥˜: {e}")
        await session.send_message('error', {'message': str(e)})
    finally:
        session.is_active = False
        logger.info(f"[{session_id}] ì„¸ì…˜ ì¢…ë£Œ")


@router.get("/vad/status")
async def vad_status():
    """Hybrid VAD ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸"""
    try:
        # Hybrid VAD í…ŒìŠ¤íŠ¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        silero_vad = SileroVADStream(
            sample_rate=16000,
            frame_ms=40,
            threshold=0.3,
        )
        hybrid_vad = HybridVADStream(
            silero_vad,
            sample_rate=16000,
            frame_ms=30,
            aggressiveness=3,
            mode="and",
        )
        return {
            'status': 'ok',
            'engine': 'hybrid',
            'mode': hybrid_vad.mode,
            'silero_threshold': silero_vad.threshold,
            'webrtc_aggressiveness': 3,
            'sample_rate': hybrid_vad.sample_rate,
        }
    except Exception as e:
        return {
            'status': 'error',
            'message': str(e)
        }

