"""
VibeVoice í•œê¸€ TTS ì›¹ ì¸í„°í˜ì´ìŠ¤
Gradioë¥¼ ì‚¬ìš©í•œ ê°„ë‹¨í•œ ì›¹ UI

ì‹¤í–‰: python web_tts.py
ì ‘ì†: http://localhost:7860
"""
import gradio as gr
import os
import sys
import time
import copy
import traceback as tb

def generate_speech(text, speaker_name, cfg_scale):
    """í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜"""
    if not text or not text.strip():
        return None, "âŒ í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”."
    
    try:
        import torch
        from vibevoice.modular.modeling_vibevoice_streaming_inference import VibeVoiceStreamingForConditionalGenerationInference
        from vibevoice.processor.vibevoice_streaming_processor import VibeVoiceStreamingProcessor
        
        # í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬
        text = text.strip().replace("'", "'").replace('"', '"').replace('"', '"')
        
        # ë””ë°”ì´ìŠ¤ ì„¤ì •
        if torch.cuda.is_available():
            device = 'cuda'
        elif torch.backends.mps.is_available():
            device = 'mps'
        else:
            device = 'cpu'
        
        status_msg = f"ğŸ–¥ï¸ ë””ë°”ì´ìŠ¤: {device}\n"
        
        # ëª¨ë¸ ë¡œë“œ (ì „ì—­ ë³€ìˆ˜ë¡œ ìºì‹±í•˜ë©´ ë” ë¹ ë¦„)
        model_path = 'microsoft/VibeVoice-Realtime-0.5B'
        
        status_msg += f"ğŸ“¦ ëª¨ë¸ ë¡œë”© ì¤‘...\n"
        processor = VibeVoiceStreamingProcessor.from_pretrained(model_path)
        
        # ë””ë°”ì´ìŠ¤ë³„ ì„¤ì •
        if device == 'mps':
            load_dtype = torch.float32
            attn_impl = 'sdpa'
        elif device == 'cuda':
            load_dtype = torch.bfloat16
            attn_impl = 'flash_attention_2'
        else:
            load_dtype = torch.float32
            attn_impl = 'sdpa'
        
        try:
            if device == 'mps':
                model = VibeVoiceStreamingForConditionalGenerationInference.from_pretrained(
                    model_path, torch_dtype=load_dtype, attn_implementation=attn_impl, device_map=None
                )
                model.to('mps')
            elif device == 'cuda':
                model = VibeVoiceStreamingForConditionalGenerationInference.from_pretrained(
                    model_path, torch_dtype=load_dtype, device_map='cuda', attn_implementation=attn_impl
                )
            else:
                model = VibeVoiceStreamingForConditionalGenerationInference.from_pretrained(
                    model_path, torch_dtype=load_dtype, device_map='cpu', attn_implementation=attn_impl
                )
        except:
            model = VibeVoiceStreamingForConditionalGenerationInference.from_pretrained(
                model_path, torch_dtype=load_dtype, 
                device_map=(device if device in ('cuda', 'cpu') else None), 
                attn_implementation='sdpa'
            )
            if device == 'mps':
                model.to('mps')
        
        model.eval()
        model.set_ddpm_inference_steps(num_steps=5)
        
        # í™”ì ìŒì„± íŒŒì¼ ì°¾ê¸°
        possible_voice_dirs = [
            os.path.join('VibeVoice', 'demo', 'voices', 'streaming_model'),
            os.path.join(os.path.expanduser('~'), 'VibeVoice', 'demo', 'voices', 'streaming_model'),
        ]
        
        voice_file = None
        for voice_dir in possible_voice_dirs:
            if os.path.exists(voice_dir):
                for filename in os.listdir(voice_dir):
                    if filename.endswith('.pt') and speaker_name.lower() in filename.lower():
                        voice_file = os.path.join(voice_dir, filename)
                        break
                if voice_file:
                    break
        
        if not voice_file or not os.path.exists(voice_file):
            return None, f"âŒ '{speaker_name}' í™”ì íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\nVibeVoice/demo/voices/streaming_model/ í´ë”ë¥¼ í™•ì¸í•˜ì„¸ìš”."
        
        status_msg += f"ğŸ¤ í™”ì: {speaker_name}\n"
        
        target_device = device if device != 'cpu' else 'cpu'
        all_prefilled_outputs = torch.load(voice_file, map_location=target_device, weights_only=False)
        
        # ì…ë ¥ ì¤€ë¹„
        inputs = processor.process_input_with_cached_prompt(
            text=text, cached_prompt=all_prefilled_outputs,
            padding=True, return_tensors='pt', return_attention_mask=True
        )
        
        for k, v in inputs.items():
            if torch.is_tensor(v):
                inputs[k] = v.to(target_device)
        
        # ìŒì„± ìƒì„±
        status_msg += f"ğŸµ ìŒì„± ìƒì„± ì¤‘...\n"
        start_time = time.time()
        
        outputs = model.generate(
            **inputs, max_new_tokens=None, cfg_scale=cfg_scale,
            tokenizer=processor.tokenizer, generation_config={'do_sample': False},
            verbose=False,
            all_prefilled_outputs=copy.deepcopy(all_prefilled_outputs) if all_prefilled_outputs is not None else None
        )
        
        generation_time = time.time() - start_time
        
        # í†µê³„
        if outputs.speech_outputs and outputs.speech_outputs[0] is not None:
            sample_rate = 24000
            audio_samples = outputs.speech_outputs[0].shape[-1]
            audio_duration = audio_samples / sample_rate
            rtf = generation_time / audio_duration
            
            status_msg += f"â±ï¸ ìƒì„± ì‹œê°„: {generation_time:.2f}ì´ˆ\n"
            status_msg += f"ğŸ¶ ì˜¤ë””ì˜¤ ê¸¸ì´: {audio_duration:.2f}ì´ˆ\n"
            status_msg += f"âš¡ RTF: {rtf:.2f}x\n"
            status_msg += "âœ… ì™„ë£Œ!"
            
            # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
            output_path = "temp_output.wav"
            processor.save_audio(outputs.speech_outputs[0], output_path=output_path)
            
            return output_path, status_msg
        else:
            return None, "âŒ ìŒì„± ìƒì„± ì‹¤íŒ¨"
            
    except ImportError as e:
        error_msg = f"âŒ ë¼ì´ë¸ŒëŸ¬ë¦¬ import ì‹¤íŒ¨: {e}\n\n"
        error_msg += "ğŸ“Œ í•´ê²° ë°©ë²•:\n"
        error_msg += "1. pip install -r requirements.txt\n"
        error_msg += "2. git clone https://github.com/microsoft/VibeVoice.git\n"
        error_msg += "3. cd VibeVoice && pip install -e ."
        return None, error_msg
    except Exception as e:
        error_msg = f"âŒ ì—ëŸ¬ ë°œìƒ: {e}\n\n"
        error_msg += tb.format_exc()
        return None, error_msg

# Gradio ì¸í„°í˜ì´ìŠ¤
with gr.Blocks(title="VibeVoice í•œê¸€ TTS") as demo:
    gr.Markdown("""
    # ğŸ™ï¸ VibeVoice í•œê¸€ TTS ì„œë¹„ìŠ¤
    
    Microsoftì˜ VibeVoice-Realtime-0.5B ëª¨ë¸ì„ ì‚¬ìš©í•œ Text-to-Speech ì›¹ ì¸í„°í˜ì´ìŠ¤ì…ë‹ˆë‹¤.
    
    > âš ï¸ **ì£¼ì˜**: ì´ ì„œë¹„ìŠ¤ëŠ” ê³µì‹ì ìœ¼ë¡œ ì˜ì–´ ì „ìš©ì´ì§€ë§Œ, ì‹¤í—˜ì ìœ¼ë¡œ í•œê¸€ë„ ì§€ì›í•©ë‹ˆë‹¤.
    """)
    
    with gr.Row():
        with gr.Column():
            text_input = gr.Textbox(
                label="ë³€í™˜í•  í…ìŠ¤íŠ¸",
                placeholder="ì—¬ê¸°ì— í•œê¸€ í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”...",
                lines=5
            )
            
            speaker_dropdown = gr.Dropdown(
                choices=["Carter", "Wayne", "Emma", "Lily"],
                value="Carter",
                label="í™”ì ì„ íƒ"
            )
            
            cfg_slider = gr.Slider(
                minimum=1.0,
                maximum=3.0,
                value=1.5,
                step=0.1,
                label="CFG Scale (ìŒì„± í’ˆì§ˆ ì¡°ì ˆ)"
            )
            
            generate_btn = gr.Button("ğŸµ ìŒì„± ìƒì„±", variant="primary")
        
        with gr.Column():
            audio_output = gr.Audio(label="ìƒì„±ëœ ìŒì„±", type="filepath")
            status_output = gr.Textbox(label="ìƒíƒœ", lines=10)
    
    # ì˜ˆì‹œ í…ìŠ¤íŠ¸
    gr.Examples(
        examples=[
            ["ì•ˆë…•í•˜ì„¸ìš”. VibeVoice í•œê¸€ TTS í…ŒìŠ¤íŠ¸ì…ë‹ˆë‹¤.", "Carter", 1.5],
            ["ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì°¸ ì¢‹ë„¤ìš”. ì—¬ëŸ¬ë¶„ì˜ í•˜ë£¨ê°€ í–‰ë³µí•˜ê¸°ë¥¼ ë°”ëë‹ˆë‹¤.", "Wayne", 1.5],
            ["ì¸ê³µì§€ëŠ¥ ìŒì„± í•©ì„± ê¸°ìˆ ì´ ì ì  ë°œì „í•˜ê³  ìˆìŠµë‹ˆë‹¤.", "Carter", 1.5],
        ],
        inputs=[text_input, speaker_dropdown, cfg_slider],
    )
    
    # ì´ë²¤íŠ¸ ì—°ê²°
    generate_btn.click(
        fn=generate_speech,
        inputs=[text_input, speaker_dropdown, cfg_slider],
        outputs=[audio_output, status_output]
    )

if __name__ == "__main__":
    print("ğŸš€ VibeVoice ì›¹ ì¸í„°í˜ì´ìŠ¤ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
    print("ğŸ“Œ ë¸Œë¼ìš°ì €ì—ì„œ http://localhost:7860 ìœ¼ë¡œ ì ‘ì†í•˜ì„¸ìš”.")
    print()
    demo.launch(server_name="0.0.0.0", server_port=7860, share=False)
