import os
from dotenv import load_dotenv
from openai import OpenAI
import streamlit as st

load_dotenv()

st.set_page_config(
    page_title="ê¸ˆìœµ AICC AI ì—ì´ì „íŠ¸ - ì‹¤ì‹œê°„ ìƒë‹´",
    layout="wide"
)


LLM_MODE = os.getenv("AGENT_LLM_MODE", "mock").lower()
client = None

if LLM_MODE != "mock":
    try:
        api_key = os.environ["OPENAI_API_KEY"]
    except KeyError:
        st.error("ğŸš¨ OpenAI API Keyê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•´ ì£¼ì„¸ìš”.")
        st.stop()

    try:
        client = OpenAI(api_key=api_key)
    except Exception as exc:
        st.error(f"ğŸš¨ OpenAI ì´ˆê¸°í™” ì˜¤ë¥˜: {exc}")
        st.stop()
else:
    st.info("í˜„ì¬ ìƒë‹´ì› ì‹œë®¬ë ˆì´ì…˜ì€ Mock ëª¨ë“œë¡œ ë™ì‘í•©ë‹ˆë‹¤. ì‹¤ì œ ëª¨ë¸ì„ ì‚¬ìš©í•˜ë ¤ë©´ `AGENT_LLM_MODE`ë¥¼ ë³€ê²½í•´ ì£¼ì„¸ìš”.")


SYSTEM_PROMPT_AGENT = """
ë‹¹ì‹ ì€ ê¸ˆìœµ ì „ë¬¸ ìƒë‹´ AI ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤. ìƒë‹´ì‚¬ì˜ ë©”ëª¨ë¥¼ ì°¸ê³ í•´ ê³ ê°ì´ ë§í•  ë²•í•œ ë¬¸ì¥ì„ ì§§ê³  ìì—°ìŠ¤ëŸ½ê²Œ ìƒì„±í•˜ì„¸ìš”.
ë‹µë³€ ì•ì—ëŠ” ë°˜ë“œì‹œ 'ê³ ê°: 'ì„ ë¶™ì´ê³ , ê³ ê°ì˜ ìš”ì²­ì„ ëª…í™•í•˜ê²Œ ë³´ì—¬ ì£¼ì„¸ìš”.
"""


analysis_data = st.session_state.get("analysis_result")

if not analysis_data:
    st.error("ğŸš¨ ì‚¬ì „ ìƒë‹´ ë¶„ì„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ê³ ê° ì±—ë´‡ í™”ë©´ì—ì„œ ìƒë‹´ì› ì—°ê²°ì„ ë¨¼ì € ì§„í–‰í•´ ì£¼ì„¸ìš”.")
    if st.button("ê³ ê°ìš© ì±—ë´‡ìœ¼ë¡œ ëŒì•„ê°€ê¸°"):
        st.warning("í˜ì´ì§€ ì´ë™ ê¸°ëŠ¥ì€ í”„ë¡œì íŠ¸ êµ¬ì¡°ì— ë§ê²Œ ì¶”ê°€ êµ¬í˜„í•´ì•¼ í•©ë‹ˆë‹¤.")
    st.stop()


def get_sentiment_label(sentiment: str) -> str:
    mapping = {
        "POSITIVE": "ğŸ™‚ ê¸ì •",
        "NEGATIVE": "â˜¹ï¸ ë¶€ì •",
        "NEUTRAL": "ğŸ˜ ì¤‘ë¦½",
    }
    return mapping.get(sentiment or "", "â“ ë¯¸í™•ì¸")


with st.sidebar:
    st.header("AI ìƒë‹´ ë³´ì¡° íŒ¨ë„")
    st.subheader("ì‚¬ì „ ìƒë‹´ ìš”ì•½")
    st.info(analysis_data.get("summary", "ìš”ì•½ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤."))

    st.subheader("ê³ ê° ë¶„ì„ ì •ë³´")
    col1, col2 = st.columns(2)
    with col1:
        st.metric("ê³ ê° ê°ì •", get_sentiment_label(analysis_data.get("customer_sentiment")))
    with col2:
        keywords = analysis_data.get("extracted_keywords", []) or []
        st.metric("í•µì‹¬ í‚¤ì›Œë“œ ìˆ˜", str(len(keywords)))

    if keywords:
        st.text(" ".join(f"#{kw}" for kw in keywords))

    st.subheader("AI ì¶”ì²œ ìë£Œ (KMS)")
    recommendations = analysis_data.get("kms_recommendations", []) or []
    if recommendations:
        for rec in recommendations:
            st.link_button(
                f"{rec['title']} (ê´€ê³„ë„ {rec['relevance_score']:.0%})",
                rec["url"]
            )
    else:
        st.text("ì¶”ì²œ ìë£Œê°€ ì—†ìŠµë‹ˆë‹¤.")

    st.markdown("---")
    st.text(f"ë¶„ì„ ì‹œê°: {analysis_data.get('timestamp', 'N/A')}")


st.title("ğŸ§‘ ì‹¤ì‹œê°„ ìƒë‹´ ì„¸ì…˜")
st.caption("AI Agent v1.0 - ìƒë‹´ ì˜ˆì¸¡ ë³´ì¡° ì‹œë®¬ë ˆì´ì…˜")


if "agent_messages" not in st.session_state:
    initial_summary = analysis_data.get("summary", "ìš”ì•½ ì •ë³´ ì—†ìŒ")
    intro_message = f"ì‹œìŠ¤í…œ: ì•„ë˜ëŠ” ê³ ê° ì±—ë´‡ ë¶„ì„ ìš”ì•½ì…ë‹ˆë‹¤.\n\n---\n{initial_summary}"
    st.session_state["agent_messages"] = [
        {"role": "system", "content": intro_message},
        {"role": "user", "content": "ê³ ê°: ì±—ë´‡ ìƒë‹´ ë‚´ìš©ì„ ìƒë‹´ì›ì—ê²Œ ë‹¤ì‹œ í™•ì¸ë°›ê³  ì‹¶ìŠµë‹ˆë‹¤."},
    ]


def render_chat_history():
    for entry in st.session_state["agent_messages"]:
        role = "assistant" if entry["role"] in {"system", "assistant"} else "user"
        with st.chat_message(role):
            st.markdown(entry["content"])


def predict_customer_reply(api_messages):
    if LLM_MODE == "mock":
        last_note = next(
            (msg["content"] for msg in reversed(st.session_state["agent_messages"]) if msg["role"] == "assistant"),
            ""
        )
        memo_text = last_note.replace("ìƒë‹´ ë©”ëª¨:", "").strip() or "ìƒë‹´ ë©”ëª¨ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë„ì™€ì£¼ì„¸ìš”."
        return f"ê³ ê°: ë°©ê¸ˆ ë‚¨ê²¨ì£¼ì‹  '{memo_text}' ë‚´ìš©ì— ëŒ€í•´ ì¡°ê¸ˆ ë” ì„¤ëª…í•´ ì£¼ì‹¤ ìˆ˜ ìˆë‚˜ìš”?"

    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=api_messages,
    )
    return response.choices[0].message.content


render_chat_history()


if prompt := st.chat_input("ìƒë‹´ ë©”ëª¨ ë˜ëŠ” ê³ ê° ì˜ˆìƒ ì§ˆë¬¸ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”."):
    memo_text = f"ìƒë‹´ ë©”ëª¨: {prompt}"
    st.session_state["agent_messages"].append({"role": "assistant", "content": memo_text})

    with st.chat_message("assistant"):
        st.markdown(memo_text)

    with st.chat_message("user"):
        with st.spinner("AI ì—ì´ì „íŠ¸ê°€ ê³ ê° ì‘ë‹µì„ ì˜ˆì¸¡í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
            api_messages = [{"role": "system", "content": SYSTEM_PROMPT_AGENT}]
            for msg in st.session_state["agent_messages"]:
                if msg["role"] != "system":
                    api_messages.append({"role": msg["role"], "content": msg["content"]})

            try:
                reply = predict_customer_reply(api_messages)
                st.markdown(reply)
                st.session_state["agent_messages"].append({"role": "user", "content": reply})
            except Exception as exc:
                st.error(f"ğŸš¨ ê³ ê° ì‘ë‹µ ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {exc}")


st.markdown("---")
st.subheader("ìƒë‹´ í›„ì† ìë™í™”")
if st.button("âœ… ë°±ì˜¤í”¼ìŠ¤ ìë™ ì²˜ë¦¬ ì™„ë£Œ (CRM/DB ì—…ë°ì´íŠ¸)", use_container_width=True):
    st.success("ë°±ì˜¤í”¼ìŠ¤ ì‹œìŠ¤í…œì— ìƒë‹´ ìš”ì•½ê³¼ ë©”ëª¨ê°€ ë°˜ì˜ë˜ì—ˆìŠµë‹ˆë‹¤.")
    st.toast("ì²˜ë¦¬ ì™„ë£Œ!", icon="âœ…")
