import streamlit as st
import requests
import uuid
import time
import os

# --- ë°±ì—”ë“œ ì„¤ì • ---
BACKEND_URL = os.getenv("BACKEND_URL", "mock")  # ê¸°ë³¸ì€ ëª© ëª¨ë“œ


def _is_mock_mode():
    return BACKEND_URL.lower() == "mock"


def _mock_chat_response(payload):
    user_message = payload.get("user_message", "")
    return {
        "ai_message": f"(Mock) '{user_message}' ë¬¸ì˜ë¥¼ í™•ì¸í–ˆìŠµë‹ˆë‹¤.",
        "source_documents": [
            {"source": "FAQ.pdf", "page": 1, "score": 0.95},
            {"source": "ì•½ê´€ì§‘.pdf", "page": 3, "score": 0.88},
        ],
    }


def _mock_handover_response(_payload):
    return {
        "status": "success",
        "analysis_result": {
            "customer_sentiment": "POSITIVE",
            "summary": "ìƒë‹´ì› ì—°ê²° ìš”ì²­ ì´ì „ì— ëª¨ì˜ ì‘ë‹µìœ¼ë¡œ ì§„í–‰ë˜ì—ˆìŠµë‹ˆë‹¤.",
            "extracted_keywords": ["ëª¨ì˜", "ìƒë‹´ì› ì—°ê²°", "í…ŒìŠ¤íŠ¸"],
            "kms_recommendations": [
                {
                    "title": "Mock ìƒí’ˆ ì•ˆë‚´ì„œ",
                    "url": "http://example.com/mock-guide",
                    "relevance_score": 0.91,
                }
            ],
        },
    }


def call_backend(path: str, payload: dict):
    if _is_mock_mode():
        if path == "/api/v1/chat/message":
            return _mock_chat_response(payload)
        if path == "/api/v1/handover/analyze":
            return _mock_handover_response(payload)
        raise ValueError(f"Mock mode does not support path: {path}")

    response = requests.post(
        f"{BACKEND_URL}{path}",
        json=payload,
        timeout=10,
    )
    response.raise_for_status()
    return response.json()

# --- í˜ì´ì§€ ì„¤ì • ---
st.set_page_config(
    page_title="AICC MVP ê³ ê°ìš© ì±—ë´‡ (ì‚¬ì „ ìƒë‹´)",
    layout="wide"
)

st.title("ğŸ¤– AICC MVP ê³ ê°ìš© ì±—ë´‡")
st.caption("ì½œì„¼í„° ì—°ê²° ì „, ë¬¸ì˜ ë‚´ìš© ì‚¬ì „ ì •ë¦¬")

# --- ì„¸ì…˜ ID ë° ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™” ---
if "session_id" not in st.session_state:
    st.session_state.session_id = str(uuid.uuid4())
    st.session_state.chatbot_messages = [
        {"role": "assistant", "content": "ì•ˆë…•í•˜ì„¸ìš”. ì€í–‰ AI ì±—ë´‡ì…ë‹ˆë‹¤. ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"}
    ]

# --- ëŒ€í™” ê¸°ë¡ í‘œì‹œ ---
for message in st.session_state.chatbot_messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])
        # ë‹µë³€ì— ê·¼ê±° ë¬¸ì„œê°€ ìˆëŠ” ê²½ìš° í•¨ê»˜ í‘œì‹œ
        if "sources" in message and message["sources"]:
            with st.expander("ì°¸ê³  ìë£Œ"):
                for source in message["sources"]:
                    st.info(f"ë¬¸ì„œ: {source['source']} (í˜ì´ì§€: {source['page']}, ê´€ë ¨ë„: {source['score']:.2f})")

# --- ìƒˆë¡œìš´ ì…ë ¥ ì²˜ë¦¬ ë° ë°±ì—”ë“œ API í˜¸ì¶œ ---
if prompt := st.chat_input("ë¬¸ì˜ ë‚´ìš©ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”."):
    
    # ê³ ê° ì…ë ¥ ì¶”ê°€ ë° í‘œì‹œ
    st.session_state.chatbot_messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # ë°±ì—”ë“œ APIë¡œ ì±—ë´‡ ì‘ë‹µ ìš”ì²­
    with st.chat_message("assistant"):
        with st.spinner("AI ì±—ë´‡ì´ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘..."):
            try:
                api_response = call_backend(
                    "/api/v1/chat/message",
                    {"session_id": st.session_state.session_id, "user_message": prompt},
                )
                ai_message = api_response.get("ai_message", "ì£„ì†¡í•©ë‹ˆë‹¤. ë‹µë³€ì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                source_documents = api_response.get("source_documents", [])
                
                st.markdown(ai_message)
                
                # ë‹µë³€ ë° ê·¼ê±° ìë£Œë¥¼ ì„¸ì…˜ì— ì €ì¥
                st.session_state.chatbot_messages.append({
                    "role": "assistant", 
                    "content": ai_message,
                    "sources": source_documents # ê·¼ê±° ìë£Œ ì €ì¥
                })

                # ê·¼ê±° ìë£Œê°€ ìˆìœ¼ë©´ í•¨ê»˜ í‘œì‹œ
                if source_documents:
                    with st.expander("ì°¸ê³  ìë£Œ"):
                        for source in source_documents:
                            st.info(f"ë¬¸ì„œ: {source['source']} (í˜ì´ì§€: {source['page']}, ê´€ë ¨ë„: {source['score']:.2f})")

            except requests.exceptions.RequestException as e:
                st.error(f"ğŸš¨ API ìš”ì²­ ì˜¤ë¥˜: {e}")
            except Exception as e:
                st.error(f"ğŸš¨ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")


# --- ëŒ€í™” ì¢…ë£Œ ë° ìƒë‹´ì› ì—°ê²° ë¡œì§ ---
st.markdown("---")

if st.button("ì „ë¬¸ ìƒë‹´ì› ì—°ê²° ìš”ì²­"):
    with st.spinner("ëŒ€í™” ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ ìƒë‹´ì›ì—ê²Œ ì „ë‹¬í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
        try:
            # 1. ë°±ì—”ë“œì— ë¶„ì„ ìš”ì²­
            analysis_data = call_backend(
                "/api/v1/handover/analyze",
                {"session_id": st.session_state.session_id, "trigger_reason": "USER_REQUEST"},
            )
            
            # 2. ë¶„ì„ ê²°ê³¼ë¥¼ ì„¸ì…˜ ìƒíƒœì— ì €ì¥ (ë‹¤ìŒ í˜ì´ì§€ì—ì„œ ì‚¬ìš©)
            st.session_state.analysis_result = analysis_data.get("analysis_result")
            
            st.success("âœ… ëŒ€í™” ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ìƒë‹´ì› í™”ë©´ìœ¼ë¡œ ì´ë™í•´ì£¼ì„¸ìš”.")
            st.toast("ë¶„ì„ ì™„ë£Œ!", icon='ğŸ‰')
            
            # 3. í˜„ì¬ ì±—ë´‡ì˜ ëŒ€í™” ë‚´ìš©ì€ ì´ˆê¸°í™”
            # st.session_state.chatbot_messages = [] # í•„ìš” ì‹œ ì£¼ì„ í•´ì œ
            
            # 4. (ì˜µì…˜) ë‹¤ìŒ í˜ì´ì§€ë¡œ ìë™ ì´ë™
            # time.sleep(1)
            # st.switch_page("pages/01_consultation_session.py") # íŒŒì¼ ê²½ë¡œ í™•ì¸ í•„ìš”

        except requests.exceptions.RequestException as e:
            st.error(f"ğŸš¨ ë¶„ì„ API ìš”ì²­ ì˜¤ë¥˜: {e}")
        except Exception as e:
            st.error(f"ğŸš¨ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

if "analysis_result" in st.session_state:
    st.info("ìƒë‹´ì› ì—°ê²°ì´ ìš”ì²­ë˜ì—ˆìŠµë‹ˆë‹¤. ì•„ë˜ ë²„íŠ¼ì„ ëˆŒëŸ¬ ìƒë‹´ì› í™”ë©´ìœ¼ë¡œ ì´ë™í•˜ì„¸ìš”.")
    if st.button("ìƒë‹´ì› í™”ë©´ìœ¼ë¡œ ì´ë™"):
        st.switch_page("pages/01_consultation_session.py")
